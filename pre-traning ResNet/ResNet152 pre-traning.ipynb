{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import models\n",
    "from torch.autograd import Variable\n",
    "import torchsummary as summary\n",
    "import os\n",
    "import csv\n",
    "import codecs\n",
    "import numpy as np\n",
    "import time\n",
    "from thop import profile\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "'''Define Hyperparameters'''\n",
    "EPOCH = 150\n",
    "batch_size=512\n",
    "classes_num=1000\n",
    "learning_rate=1e-3\n",
    "\n",
    "'''定义Transform'''\n",
    " #对训练集做一个变换\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "train_dir = \"D:/Dateset/Alldataset/Imagenet/ILSVRC2012_img_train\"        \n",
    "#train_dir = \"D:/Dateset/Alldataset/mini-imagenet/train\"\n",
    "#train_dir = \"D:/2021year/CVPR/PermuteNet-main/CNNonMNIST/data/trainNum_T/test\"\n",
    "#define dataset\n",
    "train_datasets = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "#load dataset\n",
    "train_dataloader = torch.utils.data.DataLoader(train_datasets, batch_size=batch_size, shuffle=True,num_workers=8,pin_memory=True)#,num_workers=16,pin_memory=False\n",
    "\n",
    "#val_dir = \"D:/Dateset/Alldataset/mini-imagenet/val\"\n",
    "#val_dir = \"D:/2021year/CVPR/PermuteNet-main/CNNonMNIST/data/trainNum_T/val\"\n",
    "val_dir = \"D:/Dateset/Alldataset/Imagenet/ILSVRC2012_img_val1\"\n",
    "val_datasets = datasets.ImageFolder(val_dir, transform=val_transforms)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_datasets, batch_size=batch_size, shuffle=True,num_workers=8,pin_memory=True)#,num_workers=16,pin_memory=True\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    '''it can be build ResNet18 and ResNet34'''\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = torch.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    '''it can be build ResNet50 or deeper block'''\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(nn.Conv2d(in_planes, self.expansion*planes,kernel_size=1, stride=stride, bias=False),\n",
    "                                          nn.BatchNorm2d(self.expansion*planes))\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = torch.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = torch.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=classes_num):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.classifier = nn.Linear(512*block.expansion, num_classes)#\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out_x1 = self.relu(out)\n",
    "        out_x2 = self.maxpool(out_x1)\n",
    "        out1 = self.layer1(out_x2)    #56*56      4\n",
    "        out2 = self.layer2(out1)    #28*28        4\n",
    "        out3 = self.layer3(out2)    #14*14        4\n",
    "        out4 = self.layer4(out3)   #(512*7*7)     4\n",
    "        #out5 = F.avg_pool2d(out4, 4)\n",
    "        out5 = self.avgpool(out4 )\n",
    "        out6 = out5.view(out5.size(0),-1)#reshape\n",
    "        out7 = self.classifier(out6)\n",
    "        return out7\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
    "#--------------------traning---------------------------------\n",
    "model = ResNet152()#here is your model\n",
    "summary.summary(model, input_size=(3,224,224),device=\"cpu\")\n",
    "\n",
    "params = [{'params': md.parameters()} for md in model.children()\n",
    "          if md in [model.classifier]]\n",
    "#optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01,momentum=0.9, weight_decay=1e-4)\n",
    "StepLR    = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "#存储测试loss和acc\n",
    "Loss_list = []\n",
    "Accuracy_list = []\n",
    "#存储训练loss和acc\n",
    "train_Loss_list = []\n",
    "train_Accuracy_list = []\n",
    "#这俩作用是为了提前开辟一个\n",
    "loss = []\n",
    "loss1 = []\n",
    "def train_res(model,train_dataloader,epoch):\n",
    "    model.train()\n",
    "    #print('epoch {}'.format(epoch + 1))\n",
    "    # training-----------------------------\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    for batch_x, batch_y in train_dataloader:\n",
    "        batch_x  = Variable(batch_x).cuda()\n",
    "        batch_y  = Variable(batch_y).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch_x)\n",
    "        loss1 = loss_func(out, batch_y)\n",
    "        train_loss += loss1.item()\n",
    "        pred = torch.max(out, 1)[1]\n",
    "        train_correct = (pred == batch_y).sum()\n",
    "        train_acc += train_correct.item()\n",
    "        loss1.backward()\n",
    "        optimizer.step()\n",
    "    print('Train Loss: {:.6f}, Acc: {:.6f}'.format(train_loss / (len(train_datasets)), train_acc / (len(train_datasets))))#输出训练时的loss和acc\n",
    "    train_Loss_list.append(train_loss / (len(val_datasets)))\n",
    "    train_Accuracy_list.append(100 * train_acc / (len(val_datasets)))\n",
    "\n",
    "# evaluation--------------------------------\n",
    "def val(model,val_dataloader):\n",
    "    model.eval()\n",
    "    eval_loss= 0.\n",
    "    eval_acc = 0.\n",
    "    for batch_x, batch_y in val_dataloader:\n",
    "        batch_x = Variable(batch_x, volatile=True).cuda()\n",
    "        batch_y = Variable(batch_y, volatile=True).cuda()\n",
    "        out = model(batch_x)\n",
    "        loss = loss_func(out, batch_y)\n",
    "        eval_loss += loss.item()\n",
    "        pred = torch.max(out, 1)[1]\n",
    "        num_correct = (pred == batch_y).sum()\n",
    "        eval_acc += num_correct.item()\n",
    "    print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(val_datasets)), eval_acc / (len(val_datasets))))#输出测试时的loss和acc\n",
    "    Loss_list.append(eval_loss / (len(val_datasets)))\n",
    "    Accuracy_list.append(100 * eval_acc / (len(val_datasets)))\n",
    "        \n",
    "# save model\n",
    "#torch.save(model.state_dict(), 'ResNet18.pth')\n",
    "#state = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch}\n",
    "#torch.save(state, 'ResNet18.pth')\n",
    "\n",
    "\n",
    "log_dir = 'D:/2021year/CVPR/PermuteNet-main/Keras_position/Pytorch_Code/resnet18.pth'\n",
    "def main():\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    test_flag = False\n",
    "    if test_flag:\n",
    "        checkpoint = torch.load(log_dir)\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        val(model, val_dataloader)\n",
    "        return\n",
    "\n",
    "    if os.path.exists(log_dir) and test_flag:\n",
    "        checkpoint = torch.load(log_dir)\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        print('load epoch {}！'.format(start_epoch))\n",
    "    else:\n",
    "        start_epoch = 1\n",
    "        print('restart traning！')\n",
    "\n",
    "    for epoch in range(start_epoch, EPOCH):\n",
    "        since = time.time()\n",
    "        print('epoch {}'.format(epoch))\n",
    "        train_res(model, train_dataloader, epoch)\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        epoch_num = epoch/10\n",
    "        epoch_numcl = [1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0]\n",
    "        print('epoch_num',epoch_num)\n",
    "        if epoch_num in epoch_numcl:\n",
    "            print('Evaluation Model')\n",
    "            val(model, val_dataloader)\n",
    "            print('save model')\n",
    "            state = {'model':model.state_dict(), 'optimizer':optimizer.state_dict(), 'epoch':epoch}\n",
    "            torch.save(state, log_dir)\n",
    "        \n",
    "    y1 = Accuracy_list\n",
    "    y2 = Loss_list\n",
    "    y3 = train_Accuracy_list\n",
    "    y4 = train_Loss_list\n",
    "\n",
    "    x1 = range(len(Accuracy_list))\n",
    "    x2 = range(len(Loss_list))\n",
    "    x3 = range(len(train_Accuracy_list))\n",
    "    x4 = range(len(train_Loss_list))\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(x1, y1,'-')\n",
    "    plt.title('Test accuracy vs. epoches')\n",
    "    plt.ylabel('Test accuracy')\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(x2, y2,'-')\n",
    "    plt.xlabel('Test loss vs. epoches')\n",
    "    plt.ylabel('Test loss')\n",
    "    plt.show()\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(x3, y3,'-')\n",
    "    plt.title('Train accuracy vs. epoches')\n",
    "    plt.ylabel('Train accuracy')\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(x4, y4,'-')\n",
    "    plt.xlabel('Train loss vs. epoches')\n",
    "    plt.ylabel('Train loss')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
